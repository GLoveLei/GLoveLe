<!DOCTYPE html><html class="appearance-auto" lang="zh-CN"><head><meta charset="UTF-8"><title>OpenAi</title><meta name="description" content="Choose what you love"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/beautiful.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="
OpenAI库的SDK方式接入OpenAI官方同步更新了接口Api的三方库openai，版本为0.27.0，如果要使用新的模型gpt-3.5-turbo，就必须同步安装最新版本：
pip3 install openai==0.27.0
随后建立chat.py文件：
import openai

openai.api_key = &amp;quot;openai的接口apikey&amp;quot; 

completion = openai.ChatCompletion.create(
  model=&amp;quot;gpt-3.5-turbo&amp;quot;, 
  messages=[&amp;#123;&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;北国.."><script src="//unpkg.com/valine/dist/Valine.min.js"></script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Lei Gao blog" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Lei Gao's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">OpenAi</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">点击返回顶部</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#OpenAI%E5%BA%93%E7%9A%84SDK%E6%96%B9%E5%BC%8F%E6%8E%A5%E5%85%A5"><span class="toc-text">OpenAI库的SDK方式接入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ChatGPT%E8%81%8A%E5%A4%A9%E4%B8%8A%E4%B8%8B%E6%96%87"><span class="toc-text">ChatGPT聊天上下文</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%9F%E7%94%9FChatGPT%E6%8E%A5%E5%8F%A3%E5%BC%82%E6%AD%A5%E8%AE%BF%E9%97%AE"><span class="toc-text">原生ChatGPT接口异步访问</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AF%AD"><span class="toc-text">结语</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/OpenAI%E5%BA%93%E7%9A%84SDK%E6%96%B9%E5%BC%8F%E6%8E%A5%E5%85%A5"><i class="tag post-item-tag">OpenAI库的SDK方式接入</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">OpenAi</h1><time class="has-text-grey" datetime="2023-03-02T09:43:53.000Z">2023-03-02</time><article class="mt-2 post-content"><p><img src="/images/openai.jpg" alt="cover"></p>
<h2 id="OpenAI库的SDK方式接入"><a href="#OpenAI库的SDK方式接入" class="headerlink" title="OpenAI库的SDK方式接入"></a>OpenAI库的SDK方式接入</h2><p>OpenAI官方同步更新了接口Api的三方库openai，版本为0.27.0，如果要使用新的模型gpt-3.5-turbo，就必须同步安装最新版本：</p>
<pre><code>pip3 install openai==0.27.0</code></pre>
<p>随后建立chat.py文件：</p>
<pre><code class="python">import openai

openai.api_key = &quot;openai的接口apikey&quot; 

completion = openai.ChatCompletion.create(
  model=&quot;gpt-3.5-turbo&quot;, 
  messages=[&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;北国风光，千里冰封，万里雪飘，请接着续写，使用沁园春的词牌&quot;&#125;]
)

print(completion[&quot;choices&quot;][0][&quot;message&quot;][&quot;content&quot;])</code></pre>
<p>程序返回：</p>
<pre><code class="text">瑶池冰缘，雪舞凄美， 隔窗寒意，似乎钻进衣袖。
寒塘渡鸭，雪中梅影， 孤独是一片银白的姿态。
冰雪如花，开放在草莓园里， 可爱的雪人，瑟瑟发抖着欢呼。
北风凛冽，寒暄难挡， 四季明媚，但冬日尤甜美。
千里冰封，万里雪飘， 窗外天下壮观，此时正是京城美。</code></pre>
<p>闪电般秒回，让用惯了ChatGPT网页端的我们几乎不能适应。</p>
<p>gpt-3.5-turbo，对得起turbo的加成，带涡轮的ChatGPT就是不一样。</p>
<h2 id="ChatGPT聊天上下文"><a href="#ChatGPT聊天上下文" class="headerlink" title="ChatGPT聊天上下文"></a>ChatGPT聊天上下文</h2><p>我们知道ChatGPT的最大特色就是可以联系语境中的上下文，换句话说，ChatGPT可以根据之前的回答来优化之后的回答，形成上下文关系，让人机对话更加连贯和富有逻辑性。</p>
<p>这里取决于输入参数中的role参数，每一个role的取值，对应的场景不一样，其中system用于在对话开始时给ChatGPT一个指示或声明，有点像引导词，使得后续的回答更具有个性化和专业化。user是用于给用户提问的或者说是用来给用户输入引导词的。assistant顾名思义，是用于输入ChatGPT的回答内容:</p>
<pre><code class="python">import openai

openai.api_key = &quot;apikey&quot; 


class ChatGPT:
    def __init__(self,chat_list=[]) -&gt; None:
        # 初始化对话列表
        self.chat_list = []

    # 显示接口返回
    def show_conversation(self,msg_list):
        for msg in msg_list:
            if msg[&#39;role&#39;] == &#39;user&#39;:
                print(f&quot;Me: &#123;msg[&#39;content&#39;]&#125;\n&quot;)
            else:
                print(f&quot;ChatGPT: &#123;msg[&#39;content&#39;]&#125;\n&quot;)

    # 提示chatgpt
    def ask(self,prompt):
        self.chat_list.append(&#123;&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:prompt&#125;)
        response = openai.ChatCompletion.create(model=&quot;gpt-3.5-turbo&quot;,messages=self.chat_list)
        answer = response.choices[0].message[&#39;content&#39;]
        # 添加历史对话，形成上下文关系
        self.chat_list.append(&#123;&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:answer&#125;)
        self.show_conversation(self.chat_list)</code></pre>
<p>这里每一次会话都会加入chat_list的聊天列表，角色为assistant，为了让ChatGPT分析上下文，下面开始测试：</p>
<pre><code class="python">if __name__ == &#39;__main__&#39;:

    chat = ChatGPT()

    chat.ask(&quot;你是一位南宋词人，词风婉约，有点类似李清照女士，请使用蝶恋花词牌描写北国春光&quot;)</code></pre>
<p>程序返回：</p>
<pre><code class="text">Me: 你是一位南宋词人，词风婉约，有点类似李清照女士，请使用蝶恋花词牌描写北国春光

ChatGPT: 北国春光，清冽宜人。望眼欲穿的远山如翠起伏，遥远而缥缈。层层叠叠的林木，新绿徜徉，婆娑摇曳。风儿吹起，沁人心脾，点点梅花飘至，宛如仙境。

花间蝶恋，春色满园。莺莺燕燕，鸟鸣花落，时时惹人遐思。碧空万里，蓝天白云，彩云飘飘，缤纷夺目。柳絮飘飘，轻羽翩翩，小河潺潺，流水声声，婉转动人。

清风拂面，落英缤纷。听着草虫唱起，充满阳光的气息，轻轻飘荡，仿佛一条无形的小河，展开春天的美好，留下美好的记忆。人间万象，却只有这春色无边，似乎奔向远方的快乐。</code></pre>
<p>此时再次发问：</p>
<pre><code class="python">chat.ask(&quot;请使用另外一种粗狂阳刚的风格再写一遍上面的词&quot;)</code></pre>
<p>程序返回：</p>
<pre><code class="text">Me: 请使用另外一种粗狂阳刚的风格再写一遍上面的词

ChatGPT: 北国春光，不柔不媚，金色的阳光照在地上，充满了男子气概。
草原上风吹不断，那些疯狂的野花，在春风中舞蹈。
看！那些猛禽静静地盘旋在高空，监视着整片草原，威武雄壮。
花丛间，一只雄性蜂鹰跃跃欲飞，看上去仿佛要冲破天际。
这里的春天有时带着风沙，但这并不能阻止狂放豪迈的草原奔腾前行，而这样的北国春光，怎会轻易被遗忘！</code></pre>
<p>虽然内容有些尬，但确实联系了上下文。</p>
<p>需要注意的是，token不仅计算ChatGPT的接口返回内容，也会计算用户的发送内容，token的计算方法不是简单的一词一个，例如中文输入，一个中文汉字占2个字节数，而对于一次中文测试中，50个汉字被算为100个tokens，差不多是英文的一倍，而token还计算api发送中的角色字段，如果像上文一样实现上下文操作，就必须发送ChatGPT接口返回的历史聊天列表，这意味着ChatGPT上下文聊天的成本并不是我们想象中的那么低，需要谨慎使用。</p>
<h2 id="原生ChatGPT接口异步访问"><a href="#原生ChatGPT接口异步访问" class="headerlink" title="原生ChatGPT接口异步访问"></a>原生ChatGPT接口异步访问</h2><p>除了官方的SDK，新接口模型也支持原生的Http请求方式，比如使用requests库：</p>
<pre><code class="text">pip3 install requests</code></pre>
<p>直接请求openai官方接口：</p>
<pre><code class="python">import requests
h = &#123;
    &#39;Content-Type&#39;: &#39;application/json&#39;,
    &#39;Authorization&#39;: &#39;Bearer apikey&#39;
&#125;
d = &#123;
    &quot;model&quot;: &quot;gpt-3.5-turbo&quot;,
    &quot;messages&quot;:[&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请解释同步请求和异步请求的区别&quot;&#125;],
    &quot;max_tokens&quot;: 100,
    &quot;temperature&quot;: 0
&#125;
u = &#39;https://api.openai.com/v1/chat/completions&#39;
r = requests.post(url=u, headers=h, json=d).json()
print(r)</code></pre>
<p>程序返回：</p>
<pre><code class="json">&#123;&#39;id&#39;: &#39;chatcmpl-6qDNQ9O4hZPDT1Ju902coxypjO0mY&#39;, 
&#39;object&#39;: &#39;chat.completion&#39;, 
&#39;created&#39;: 1677902496, &#39;model&#39;: &#39;gpt-3.5-turbo-0301&#39;, 
&#39;usage&#39;: &#123;&#39;prompt_tokens&#39;: 20, &#39;completion_tokens&#39;: 100, &#39;total_tokens&#39;: 120&#125;, 
&#39;choices&#39;: [&#123;&#39;message&#39;: 
&#123;&#39;role&#39;: &#39;assistant&#39;, 
&#39;content&#39;: &#39;\n\n同步请求和异步请求是指在客户端向服务器发送请求时，客户端等待服务器响应的方式不同。\n\n同步请求是指客户端发送请求后，必须等待服务器响应后才能继续执行后续的代码。在等待服务器响应的过程中，客户端的界面会被阻塞，用户无法进行&#39;&#125;, 
&#39;finish_reason&#39;: &#39;length&#39;, &#39;index&#39;: 0&#125;]&#125;</code></pre>
<p>ChatGPT原生接口也支持异步方式请求，这里使用httpx:</p>
<pre><code class="text">pip3 install httpx</code></pre>
<p>编写异步请求：</p>
<pre><code class="python">h = &#123;
    &#39;Content-Type&#39;: &#39;application/json&#39;,
    &#39;Authorization&#39;: &#39;Bearer apikey&#39;
&#125;
d = &#123;
    &quot;model&quot;: &quot;gpt-3.5-turbo&quot;,
    &quot;messages&quot;:[&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请解释同步请求和异步请求的区别&quot;&#125;],
    &quot;max_tokens&quot;: 100,
    &quot;temperature&quot;: 0
&#125;
u = &#39;https://api.openai.com/v1/chat/completions&#39;

import asyncio
import httpx

async def main():
    async with httpx.AsyncClient() as client:
        resp = await client.post(url=u, headers=h, json=d)
        result = resp.json()
        print(result)

asyncio.run(main())</code></pre>
<p>程序返回:</p>
<pre><code class="json">&#123;&#39;id&#39;: &#39;chatcmpl-6qDNQ9O4hZPDT1Ju902coxypjO0mY&#39;, 
&#39;object&#39;: &#39;chat.completion&#39;, 
&#39;created&#39;: 1677902496, &#39;model&#39;: &#39;gpt-3.5-turbo-0301&#39;, 
&#39;usage&#39;: &#123;&#39;prompt_tokens&#39;: 20, &#39;completion_tokens&#39;: 100, &#39;total_tokens&#39;: 120&#125;, 
&#39;choices&#39;: [&#123;&#39;message&#39;: 
&#123;&#39;role&#39;: &#39;assistant&#39;, 
&#39;content&#39;: &#39;\n\n同步请求和异步请求是指在客户端向服务器发送请求时，客户端等待服务器响应的方式不同。\n\n同步请求是指客户端发送请求后，必须等待服务器响应后才能继续执行后续的代码。在等待服务器响应的过程中，客户端的界面会被阻塞，用户无法进行&#39;&#125;, 
&#39;finish_reason&#39;: &#39;length&#39;, &#39;index&#39;: 0&#125;]&#125;</code></pre>
<p>我们也可以将异步请求方式封装到对话类中，完整代码：</p>
<pre><code class="python">import openai
import asyncio
import httpx

openai.api_key = &quot;apikey&quot; 

h = &#123;
    &#39;Content-Type&#39;: &#39;application/json&#39;,
    &#39;Authorization&#39;: f&#39;Bearer &#123;openai.api_key&#125;&#39;
&#125;
d = &#123;
    &quot;model&quot;: &quot;gpt-3.5-turbo&quot;,
    &quot;messages&quot;:[&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请解释同步请求和异步请求的区别&quot;&#125;],
    &quot;max_tokens&quot;: 100,
    &quot;temperature&quot;: 0
&#125;
u = &#39;https://api.openai.com/v1/chat/completions&#39;


class ChatGPT:
    def __init__(self,chat_list=[]) -&gt; None:
        # 初始化对话列表
        self.chat_list = []

    # 异步访问
    async def ask_async(self,prompt):

        d[&quot;messages&quot;][0][&quot;content&quot;] = prompt
        async with httpx.AsyncClient() as client:
            resp = await client.post(url=u, headers=h, json=d)
            result = resp.json()
            print(result)


    # 显示接口返回
    def show_conversation(self,msg_list):
        for msg in msg_list:
            if msg[&#39;role&#39;] == &#39;user&#39;:
                print(f&quot;Me: &#123;msg[&#39;content&#39;]&#125;\n&quot;)
            else:
                print(f&quot;ChatGPT: &#123;msg[&#39;content&#39;]&#125;\n&quot;)

    # 提示chatgpt
    def ask(self,prompt):
        self.chat_list.append(&#123;&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:prompt&#125;)
        response = openai.ChatCompletion.create(model=&quot;gpt-3.5-turbo&quot;,messages=self.chat_list)
        answer = response.choices[0].message[&#39;content&#39;]
        # 添加历史对话，形成上下文关系
        self.chat_list.append(&#123;&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:answer&#125;)
        self.show_conversation(self.chat_list)


if __name__ == &#39;__main__&#39;:

    chat = ChatGPT()

    chat.ask(&quot;你是一位南宋词人，词风婉约，有点类似李清照女士，请使用蝶恋花词牌描写北国春光&quot;)

    chat.ask(&quot;请使用另外一种粗狂阳刚的风格再写一遍上面的词&quot;)

    asyncio.run(chat.ask_async(&quot;请解释同步请求接口和异步请求接口的区别&quot;))</code></pre>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>低成本ChatGPT接口模型gpt-3.5-turbo更容易接入三方的客户端，比如微信、QQ、钉钉群之类，比起ChatGPT网页端，ChatGPT接口的响应速度更加迅速且稳定，ChatGPT，永远的神，没有之一，且不可替代，最后奉上异步上下文封装项目，与君共觞：github.com/zcxey2911/chatgpt_api_Contextual_async</p>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2023/03/16/SchatGPT-4/" title="让ChatGPT直接编写可运行的程序代码(Python3.10实现)"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">上一页: 让ChatGPT直接编写可运行的程序代码(Python3.10实现)</span></a><a class="button is-default" href="/2022/05/23/Sid-22-05/" title="GoLang的Hugo配合nginx来打造属于自己的纯静态博客系统"><span class="has-text-weight-semibold">下一页: GoLang的Hugo配合nginx来打造属于自己的纯静态博客系统</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Haojen/Claudia-theme-blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article><article class="mt-6 comment-container" id="vcomments"></article><div id="disqus_thread"></div><article class="mt-6 comment-container" id="disqus"><script>var disqus_config = function () {this.page.url = 'null/2023/03/02/SOpenAi/';this.page.identifier = 'null';};</script><script>(function() {var d = document, s = d.createElement('script');s.src = 'https://null.disqus.com/embed.js';s.setAttribute('data-timestamp', +new Date());(d.head || d.body).appendChild(s);})();</script><script id="dsq-count-scr" src="//blog-pubgj2togw.disqus.com/count.js" async></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/glovelei"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><a title="rss" target="_blank" rel="noopener nofollow" href="/atom.xml"><i class="iconfont icon-rss"></i></a><!-- 知乎--><!-- 领英--><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright ©</span><span> Lei Gao 2023</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script></body></html>